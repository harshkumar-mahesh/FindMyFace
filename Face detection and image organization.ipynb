{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bcd9e46",
   "metadata": {},
   "source": [
    "# üìö Required Libraries\n",
    "### The following Python libraries are required for this notebook to run successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e04fa719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                           # For file and directory operations\n",
    "import cv2                          # OpenCV for image and video processing\n",
    "import numpy as np                  # For numerical operations on arrays\n",
    "import shutil                       # For high-level file operations (e.g., moving, copying files)\n",
    "from glob import glob               # For pattern matching and file path retrieval\n",
    "from tqdm import tqdm               # For displaying progress bars in loops\n",
    "from insightface.app import FaceAnalysis  # For face detection and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b3db8",
   "metadata": {},
   "source": [
    "## üîç Face Embedding & Similarity ‚Äì Step-by-Step\n",
    "### Step 1: Load InsightFace Model\n",
    "- Loads the InsightFace model with the `buffalo_l` configuration.\n",
    "- `ctx_id=0` enables GPU acceleration if available; set `ctx_id=-1` to force CPU usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74c8c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'device_id': '0', 'has_user_compute_stream': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'user_compute_stream': '0', 'gpu_external_alloc': '0', 'gpu_mem_limit': '18446744073709551615', 'enable_cuda_graph': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'do_copy_in_default_stream': '1', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'prefer_nhwc': '0', 'use_ep_level_unified_stream': '0', 'use_tf32': '1', 'sdpa_kernel': '0', 'fuse_conv_bias': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ACER/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'device_id': '0', 'has_user_compute_stream': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'user_compute_stream': '0', 'gpu_external_alloc': '0', 'gpu_mem_limit': '18446744073709551615', 'enable_cuda_graph': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'do_copy_in_default_stream': '1', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'prefer_nhwc': '0', 'use_ep_level_unified_stream': '0', 'use_tf32': '1', 'sdpa_kernel': '0', 'fuse_conv_bias': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ACER/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'device_id': '0', 'has_user_compute_stream': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'user_compute_stream': '0', 'gpu_external_alloc': '0', 'gpu_mem_limit': '18446744073709551615', 'enable_cuda_graph': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'do_copy_in_default_stream': '1', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'prefer_nhwc': '0', 'use_ep_level_unified_stream': '0', 'use_tf32': '1', 'sdpa_kernel': '0', 'fuse_conv_bias': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ACER/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'device_id': '0', 'has_user_compute_stream': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'user_compute_stream': '0', 'gpu_external_alloc': '0', 'gpu_mem_limit': '18446744073709551615', 'enable_cuda_graph': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'do_copy_in_default_stream': '1', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'prefer_nhwc': '0', 'use_ep_level_unified_stream': '0', 'use_tf32': '1', 'sdpa_kernel': '0', 'fuse_conv_bias': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ACER/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'device_id': '0', 'has_user_compute_stream': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'user_compute_stream': '0', 'gpu_external_alloc': '0', 'gpu_mem_limit': '18446744073709551615', 'enable_cuda_graph': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'do_copy_in_default_stream': '1', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'prefer_nhwc': '0', 'use_ep_level_unified_stream': '0', 'use_tf32': '1', 'sdpa_kernel': '0', 'fuse_conv_bias': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ACER/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "app = FaceAnalysis(name='buffalo_l')\n",
    "app.prepare(ctx_id=0)  # Set to 0 for GPU; use -1 for CPU fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c9fe07",
   "metadata": {},
   "source": [
    "### Step 2: Extract Face Embedding from Image\n",
    "- Detects faces in the input image.\n",
    "- Returns the normalized face embedding for the first detected face.\n",
    "- Returns None if no face is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14d55045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_embedding(image):\n",
    "    faces = app.get(image)\n",
    "    if not faces:\n",
    "        return None\n",
    "    return faces[0].normed_embedding  # Assumes single person in reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e631ea0",
   "metadata": {},
   "source": [
    "### Step 3: Compute Cosine Similarity\n",
    "- Computes the cosine similarity between two face embeddings.\n",
    "- Values range from -1 (completely different) to 1 (identical), with higher values indicating more similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23fa41d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb219c",
   "metadata": {},
   "source": [
    "### üñºÔ∏è Step 4: Load and Process Reference Image\n",
    "- Loads a reference image of the target person using OpenCV.\n",
    "- The image path should point to a clear, front-facing photo of the person you want to detect in other images.\n",
    "- If the image fails to load, it raises an error.\n",
    "- Extracts the face embedding using get_face_embedding().\n",
    "- If no face is detected in the reference image, another error is raised.\n",
    "- ‚úÖ Ensure the reference image has a clear, unobstructed view of the person's face for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45df84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_image_path = r\"F:\\\\projects\\\\Face Detector\\\\reference.jpg\"  # Replace with your clear face image\n",
    "ref_image = cv2.imread(reference_image_path)\n",
    "if ref_image is None:\n",
    "    raise ValueError(\"‚ùå Couldn't load reference image.\")\n",
    "\n",
    "ref_embedding = get_face_embedding(ref_image)\n",
    "if ref_embedding is None:\n",
    "    raise ValueError(\"‚ùå No face found in the reference image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe156e2",
   "metadata": {},
   "source": [
    "### üìÅ Step 5: Load Image Paths from Multiple Folders (Recursively)\n",
    "- Defines a list of input folders containing images.\n",
    "- Uses glob with recursive=True to search all subdirectories inside each folder.\n",
    "- Filters the results to include only valid image files (.jpg, .jpeg, .png).\n",
    "- The result is a complete list of image paths to be processed later.\n",
    "- üìå Replace \"Folder_1_path\", etc., with the actual folder paths on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folders = [\"Folder_1_path\", \"Folder_2_path\", \"Folder_3_path\"]  # Replace with your paths\n",
    "image_paths = []\n",
    "for folder in input_folders:\n",
    "    image_paths.extend(glob(os.path.join(folder, \"**\", \"*.*\"), recursive=True))\n",
    "\n",
    "# Filter only image formats\n",
    "image_paths = [p for p in image_paths if p.lower().endswith(('.jpg', '.jpeg', '.png'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d80a60c",
   "metadata": {},
   "source": [
    "### üìÇ Step 6: Create Output Folder for Detected Photos\n",
    "- Defines the name of the output folder where matched images (i.e., images containing your face) will be saved.\n",
    "- `os.makedirs(..., exist_ok=True)` ensures the folder is created if it doesn‚Äôt already exist.\n",
    "- Prevents errors in case the folder already exists by setting exist_ok=True.\n",
    "- üìÅ This folder will hold all the images where your face is detected with high similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5fbff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"my_face_photos\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0ec6f",
   "metadata": {},
   "source": [
    "### üß† Step 7: Match Faces and Save Similar Images\n",
    "#### üìù Description:\n",
    "- SIMILARITY_THRESHOLD: Controls how strict the face match is. A higher threshold (e.g. 0.7‚Äì0.8) means stricter matching; a lower threshold allows looser matches.\n",
    "\n",
    "- 1. Loops over all images with a progress bar (tqdm) and attempts to:\n",
    "- 2. Load the image using OpenCV.\n",
    "- 3. Detect faces using InsightFace.\n",
    "- 4. Calculate cosine similarity between each detected face and the reference face.\n",
    "- 5. If similarity ‚â• threshold:\n",
    "    - Copies the image to the output_folder.\n",
    "    - Stops checking other faces in that image.\n",
    "\n",
    "* ‚ö†Ô∏è You may need to tune the threshold depending on lighting, angles, or image quality. Start with 0.5‚Äì0.6 and adjust as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872046b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scanning 5770 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5770/5770 [53:43<00:00,  1.79it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Done! All matching images are saved in: my_face_photos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SIMILARITY_THRESHOLD = 0.5  # Tune based on results\n",
    "\n",
    "print(f\"üîç Scanning {len(image_paths)} images...\")\n",
    "\n",
    "for image_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    faces = app.get(img)\n",
    "    for face in faces:\n",
    "        similarity = cosine_similarity(ref_embedding, face.normed_embedding)\n",
    "        if similarity >= SIMILARITY_THRESHOLD:\n",
    "            # Copy to output folder\n",
    "            shutil.copy(image_path, os.path.join(output_folder, os.path.basename(image_path)))\n",
    "            # print(f\"‚úÖ Copied: {image_path} (similarity: {similarity:.2f})\")\n",
    "            break  # No need to check other faces in this image\n",
    "\n",
    "print(\"üéâ Done! All matching images are saved in:\", output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
